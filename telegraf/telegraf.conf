# ============================================
#  Telegraf – SQLManiak Telemetry & AI Lab
#  Dane -> InfluxDB v2 (bucket: sql_telemetry)
# ============================================

[agent]
  interval = "30s"
  round_interval = true

  metric_batch_size = 1000
  metric_buffer_limit = 10000

  collection_jitter = "0s"
  flush_interval = "10s"
  flush_jitter = "0s"

  logfile = ""
  hostname = "sql-telemetry-telegraf"
  omit_hostname = false

# =========================
#  Globalne tagi
# =========================
[global_tags]
  env = "dev"
  role = "sql-telemetry-lab"
  source = "telegraf-sqlserver"

# =========================
#  OUTPUT: InfluxDB v2
# =========================
[[outputs.influxdb_v2]]
  urls = ["http://influxdb:8086"]
  token = "dev-token"
  organization = "Demo"
  bucket = "sql_telemetry"

  # Możesz dodać wspólny tag, że to dane z Telegrafa
  [outputs.influxdb_v2.tagpass]
    source = ["telegraf-sqlserver"]

# =========================
#  INPUT: sqlserver (DMV)
# =========================
# Dokumentacja: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/sqlserver
[[inputs.sqlserver]]
  ## Lista serwerów – z perspektywy Telegrafa (w kontenerze)
  ## Łączymy się po nazwie serwisu z docker-compose: "sqlserver"
  servers = [
    "Server=sqlserver;Port=1433;User Id=sa;Password=YourStrong!Passw0rd;TrustServerCertificate=True;Application Name=Telegraf;"
  ]

  ## Query pack v2 – bardziej nowoczesne DMV
  query_version = 2

  ## Jakie zestawy zapytań z wbudowanego packa chcesz:
  ## - WaitStatsCategorized    -> kategorie waitów (do Twojego „Pulse”)
  ## - DatabaseIO              -> podstawowe I/O per baza
  ## - PerformanceCounters     -> kilka liczników wydajności
  include_query = [
    "WaitStatsCategorized",
    "DatabaseIO",
    "PerformanceCounters"
  ]

  ## Czas na wykonanie jednego zapytania
  query_timeout = "10s"

  ## Jeżeli kiedyś podłączysz Azure SQL / Managed Instance:
  # azuredb = true

  ## Dodatkowe tagi dla tego input
